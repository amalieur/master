{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File to do Porto Taxi Trajectory Similiarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1\n",
    "\n",
    "Open the code/global_variables.py file, [or just click here](global_variables.py). And edit the values to fit the given experiment, the name of the chosen subset (\"subset-*size*) and the size of the subset. As well as the coordinates of the geographical area.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2\n",
    "\n",
    "Make sure you have the needed files/folders for the chosen subset.\n",
    " - in data/raw_data there must be a .csv file with the subset of the chosen size. If not, it must be uploaded.\n",
    " - in data/raw_data there must be a .csv file with the busroutes to be used. If not, this must be uploaded.\n",
    "\n",
    " - in data/chosen_data there must be a folder with the same name as global_variables.CHOSEN_SUBSET_NAME. If not, create this empty folder.\n",
    " - in data/hashed_data there must be a folder with the same name as global_variables.CHOSEN_SUBSET_NAME. If not, create this empty folder.\n",
    " - in data there must be a folder called bus_data. If not, create this empty folder.\n",
    " - in code/experiments/results there must be a folder with the same name as global_variables.CHOSEN_SUBSET_NAME. If not create this folder.\n",
    "        - Inside this folder there must be a folder called lists, and a folder named plots. If not, create these empty folders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3\n",
    "\n",
    "Run the cells in [code/porto-data.ipynb](porto-data.ipynb), or just run the cell below.\n",
    "This will load the data from the chosen subset into the folder data/chosen_data/subset-'size', each row in the dataset is written in its own text file. It also creates a META-file which contains the name of all the text files in the subset.\n",
    "\n",
    "(Might requires to install nbformat: \"pip install nbformat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the folder: data/chosen_data/subset-5000. Files should have been generated.\n"
     ]
    }
   ],
   "source": [
    "%run \"porto-data.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4\n",
    "\n",
    "Run the cells in [code/bus-data.ipynb](bus-data.ipynb), or just run the cell below. This will load the bus data into the folder data/bus_data, each bus-route is written in its own file. It also creted a META-file which containt the name of all the text files in the subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the folder: data/bus_data/. Files should have been generated.\n"
     ]
    }
   ],
   "source": [
    "%run \"bus-data.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5\n",
    "\n",
    "Run the cells in [code/lsh-grid.ipynb](lsh-grid.ipynb), or just run the cell below. This will represent each of the rows/trajectories as an hash, and create a text file for each hashed trajectory in the folder data/hashed_data/subset-'size', as well as a META file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Check the folder: data/hashed_data/subset-5000. Hash-files should have been generated.\n"
     ]
    }
   ],
   "source": [
    "%run \"lsh-grid.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6\n",
    "Run the cells in [code/similarities-only-grid.ipynb](similarities-only-grid.ipynb), or just run the cell below. This will calculate similarities between the hashed trajectories, and create a file in code/experiments/similarities/ with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/tmp/ipykernel_3953113/192977837.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Grid Porto\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m similarities \u001b[39m=\u001b[39m generate_grid_hash_similarity(\u001b[39m\"\u001b[39;49m\u001b[39mporto\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1.6\u001b[39;49m, \u001b[39m5\u001b[39;49m)\n\u001b[1;32m     12\u001b[0m output_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../code/experiments/similarities/grid_porto-\u001b[39m\u001b[39m{\u001b[39;00mglobal_variables\u001b[39m.\u001b[39mCHOSEN_SUBSET_NAME\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m similarities\u001b[39m.\u001b[39mto_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(output_path))\n",
      "File \u001b[0;32m~/master/code/experiments/grid_similarity.py:78\u001b[0m, in \u001b[0;36mgenerate_grid_hash_similarity\u001b[0;34m(city, res, layers)\u001b[0m\n\u001b[1;32m     76\u001b[0m Grid \u001b[39m=\u001b[39m_constructGrid(city, res, layers, \u001b[39m1000\u001b[39m)\n\u001b[1;32m     77\u001b[0m hashes \u001b[39m=\u001b[39m Grid\u001b[39m.\u001b[39mcompute_dataset_hashes()\n\u001b[0;32m---> 78\u001b[0m similarities \u001b[39m=\u001b[39m py_edp_parallell(hashes)\n\u001b[1;32m     80\u001b[0m \u001b[39mreturn\u001b[39;00m similarities\n",
      "File \u001b[0;32m~/master/code/utils/similarity_measures/distance.py:79\u001b[0m, in \u001b[0;36mpy_edit_distance_penalty_parallell\u001b[0;34m(hashes)\u001b[0m\n\u001b[1;32m     77\u001b[0m pool \u001b[39m=\u001b[39m Pool(\u001b[39m12\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[39mfor\u001b[39;00m i, hash_i \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sorted_hashes\u001b[39m.\u001b[39mkeys()):\n\u001b[0;32m---> 79\u001b[0m     elements \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mmap(_fun_wrapper_edpp, [(np\u001b[39m.\u001b[39;49marray(sorted_hashes[hash_i], dtype\u001b[39m=\u001b[39;49m\u001b[39mobject\u001b[39;49m), np\u001b[39m.\u001b[39;49marray(sorted_hashes[traj_j], dtype\u001b[39m=\u001b[39;49m\u001b[39mobject\u001b[39;49m), j) \u001b[39mfor\u001b[39;49;00m j, traj_j \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(sorted_hashes\u001b[39m.\u001b[39;49mkeys()) \u001b[39mif\u001b[39;49;00m i\u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49mj])\n\u001b[1;32m     81\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m elements:\n\u001b[1;32m     82\u001b[0m         M[i, element[\u001b[39m1\u001b[39m]] \u001b[39m=\u001b[39m element[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    356\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_line_magic(\u001b[39m'\u001b[39;49m\u001b[39mrun\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msimilarities-only-grid.ipynb\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[39m'\u001b[39m\u001b[39mlocal_ns\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2482\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[39m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/site-packages/IPython/core/magics/execution.py:737\u001b[0m, in \u001b[0;36mExecutionMagics.run\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    735\u001b[0m     \u001b[39mwith\u001b[39;00m preserve_keys(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39muser_ns, \u001b[39m'\u001b[39m\u001b[39m__file__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m    736\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39muser_ns[\u001b[39m'\u001b[39m\u001b[39m__file__\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m filename\n\u001b[0;32m--> 737\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49msafe_execfile_ipy(filename, raise_exceptions\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    738\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    740\u001b[0m \u001b[39m# Control the response to exit() calls made by the script being run\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/site-packages/IPython/core/interactiveshell.py:3005\u001b[0m, in \u001b[0;36mInteractiveShell.safe_execfile_ipy\u001b[0;34m(self, fname, shell_futures, raise_exceptions)\u001b[0m\n\u001b[1;32m   3003\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrun_cell(cell, silent\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, shell_futures\u001b[39m=\u001b[39mshell_futures)\n\u001b[1;32m   3004\u001b[0m \u001b[39mif\u001b[39;00m raise_exceptions:\n\u001b[0;32m-> 3005\u001b[0m     result\u001b[39m.\u001b[39;49mraise_error()\n\u001b[1;32m   3006\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39msuccess:\n\u001b[1;32m   3007\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/site-packages/IPython/core/interactiveshell.py:308\u001b[0m, in \u001b[0;36mExecutionResult.raise_error\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    306\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_before_exec\n\u001b[1;32m    307\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_in_exec \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 308\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror_in_exec\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/tmp/ipykernel_3953113/192977837.py:11\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# Grid Porto\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m similarities \u001b[39m=\u001b[39m generate_grid_hash_similarity(\u001b[39m\"\u001b[39;49m\u001b[39mporto\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m1.6\u001b[39;49m, \u001b[39m5\u001b[39;49m)\n\u001b[1;32m     12\u001b[0m output_path \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m../code/experiments/similarities/grid_porto-\u001b[39m\u001b[39m{\u001b[39;00mglobal_variables\u001b[39m.\u001b[39mCHOSEN_SUBSET_NAME\u001b[39m}\u001b[39;00m\u001b[39m.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m similarities\u001b[39m.\u001b[39mto_csv(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mabspath(output_path))\n",
      "File \u001b[0;32m~/master/code/experiments/grid_similarity.py:78\u001b[0m, in \u001b[0;36mgenerate_grid_hash_similarity\u001b[0;34m(city, res, layers)\u001b[0m\n\u001b[1;32m     76\u001b[0m Grid \u001b[39m=\u001b[39m_constructGrid(city, res, layers, \u001b[39m1000\u001b[39m)\n\u001b[1;32m     77\u001b[0m hashes \u001b[39m=\u001b[39m Grid\u001b[39m.\u001b[39mcompute_dataset_hashes()\n\u001b[0;32m---> 78\u001b[0m similarities \u001b[39m=\u001b[39m py_edp_parallell(hashes)\n\u001b[1;32m     80\u001b[0m \u001b[39mreturn\u001b[39;00m similarities\n",
      "File \u001b[0;32m~/master/code/utils/similarity_measures/distance.py:79\u001b[0m, in \u001b[0;36mpy_edit_distance_penalty_parallell\u001b[0;34m(hashes)\u001b[0m\n\u001b[1;32m     77\u001b[0m pool \u001b[39m=\u001b[39m Pool(\u001b[39m12\u001b[39m)\n\u001b[1;32m     78\u001b[0m \u001b[39mfor\u001b[39;00m i, hash_i \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(sorted_hashes\u001b[39m.\u001b[39mkeys()):\n\u001b[0;32m---> 79\u001b[0m     elements \u001b[39m=\u001b[39m pool\u001b[39m.\u001b[39;49mmap(_fun_wrapper_edpp, [(np\u001b[39m.\u001b[39;49marray(sorted_hashes[hash_i], dtype\u001b[39m=\u001b[39;49m\u001b[39mobject\u001b[39;49m), np\u001b[39m.\u001b[39;49marray(sorted_hashes[traj_j], dtype\u001b[39m=\u001b[39;49m\u001b[39mobject\u001b[39;49m), j) \u001b[39mfor\u001b[39;49;00m j, traj_j \u001b[39min\u001b[39;49;00m \u001b[39menumerate\u001b[39;49m(sorted_hashes\u001b[39m.\u001b[39;49mkeys()) \u001b[39mif\u001b[39;49;00m i\u001b[39m>\u001b[39;49m\u001b[39m=\u001b[39;49mj])\n\u001b[1;32m     81\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m elements:\n\u001b[1;32m     82\u001b[0m         M[i, element[\u001b[39m1\u001b[39m]] \u001b[39m=\u001b[39m element[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/multiprocessing/pool.py:367\u001b[0m, in \u001b[0;36mPool.map\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m, func, iterable, chunksize\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    363\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m    364\u001b[0m \u001b[39m    Apply `func` to each element in `iterable`, collecting the results\u001b[39;00m\n\u001b[1;32m    365\u001b[0m \u001b[39m    in a list that is returned.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m \u001b[39m    '''\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_async(func, iterable, mapstar, chunksize)\u001b[39m.\u001b[39;49mget()\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwait\u001b[39m(\u001b[39mself\u001b[39m, timeout\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_event\u001b[39m.\u001b[39;49mwait(timeout)\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/threading.py:655\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    653\u001b[0m signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flag\n\u001b[1;32m    654\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 655\u001b[0m     signaled \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    656\u001b[0m \u001b[39mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m~/.conda/envs/masteroppgave/lib/python3.12/threading.py:355\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    354\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 355\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[1;32m    356\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    357\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%run \"similarities-only-grid.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7\n",
    "\n",
    "Run the code below to see the clusters created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "from experiments.hierarchical_clustering import HCA\n",
    "from experiments.davies_bouldin import davies_bouldin\n",
    "\n",
    "import global_variables\n",
    "\n",
    "best_db_value = 100\n",
    "BestGrid = None\n",
    "#TODO: update range\n",
    "highest_number_of_clusters = ceil(global_variables.CHOSEN_SUBSET_SIZE / global_variables.THRESHOLD_NUMBER_OF_TRAJECTORIES)\n",
    "for i in range (5,highest_number_of_clusters):\n",
    "    PortoGrid = HCA(\"Porto\", f\"../code/experiments/similarities/grid_porto-{global_variables.CHOSEN_SUBSET_NAME}.csv\", i )\n",
    "    result, _, _ = davies_bouldin(PortoGrid.distances, PortoGrid.clusters)\n",
    "    if result<best_db_value:\n",
    "        best_db_value = result\n",
    "        BestGrid = PortoGrid\n",
    "\n",
    "print(\"Best number of clusters is: \" + str(BestGrid.n_clusters))\n",
    "BestGrid.plot_clusters(\"Porto - Grid\")\n",
    "clusters_dict = BestGrid.get_cluster_dictionary()\n",
    "print(\"Here is the dictionary with the clusters:\")\n",
    "print(clusters_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8\n",
    "Run the cell below to run the Frechet algorithm(with a twist). It uses the clusters already created from LSH, and checks the trajectories within the same cluster for \"real\" similarity to find the well used taxi routes. Then the well used taxi routes is compared to the bus routes, to check for similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.frechet_for_taxi_case import do_whole_experiment\n",
    "\n",
    "do_whole_experiment(clusters_dict, raw_df, raw_df_bus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Step 9)\n",
    "Run the cells in [code/results-visualisation.ipynb](results-visualisation.ipynb), or just run the cell below. This will create visualisation of the results, and save them to the folder \"code/experiments/results/subset-'size'/plots\" as html pages, which can be opened in a web browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run \"results-visualisation.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Step 10)\n",
    "If you want to see the visualisations of the results in this notebook, run the cell below. Update the name of the result you want to see, check folder code/experiments/results/subset-'size'/lists to see all results which can be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update this parameter depending on which result you want to view.\n",
    "# All files in folder code/experiments/results/subset-'size'/lists can be chosen. Eg. match-0.csv, not-match-0-csv.\n",
    "#name_of_file = \"match-0.csv\"\n",
    "\n",
    "#plot = plot_result(f\"experiments/results/{global_variables.CHOSEN_SUBSET_NAME}/lists/{name_of_file}\")\n",
    "#plot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masteroppgave",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
